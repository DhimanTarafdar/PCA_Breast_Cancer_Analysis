# ЁЯУК PCA Analysis on Breast Cancer Dataset

## ЁЯУМ Dataset Overview
We used the Breast Cancer Wisconsin Dataset which contains:
- Total Samples: 569
- Original Features: 30
- Target Shape: (569,)

ржПржЗ dataset ржЯрж┐ binary classification problem ржПрж░ ржЬржирзНржп ржмрзНржпржмрж╣рзГржд рж╣рзЯ
(Benign vs Malignant tumor classification)ред

---

## ЁЯУИ Descriptive Statistics (Before PCA)
ржкрзНрж░ржержорзЗ dataset ржПрж░ basic statistical properties analyze ржХрж░рж╛ рж╣рзЯрзЗржЫрзЗ:

For each feature we calculated:
- Mean
- Standard Deviation (std)
- Minimum value
- Maximum value

Example features include:
- mean radius
- mean texture
- mean perimeter
- mean area
- mean smoothness
- mean compactness
- mean concavity
- mean concave points
- mean symmetry
- mean fractal dimension

ЁЯСЙ Observation:
Features ржЧрзБрж▓рзЛрж░ scale ржнрж┐ржирзНржи рж╣ржУрзЯрж╛рзЯ PCA ржХрж░рж╛рж░ ржЖржЧрзЗ data standardization ржЕрждрзНржпржирзНржд ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржЫрж┐рж▓ред

---

## ЁЯФД Principal Component Analysis (PCA)

### тЦ╢ Explained Variance Ratio
PCA ржХрж░рж╛рж░ ржкрж░ ржкрзНрж░ржержо 10ржЯрж┐ Principal Component ржирзЗржУрзЯрж╛ рж╣рзЯрзЗржЫрзЗред

Explained Variance Ratio:
PC1  = 44.27%  
PC2  = 18.97%  
PC3  =  9.39%  
PC4  =  6.60%  
PC5  =  5.49%  
PC6  =  4.02%  
PC7  =  2.25%  
PC8  =  1.59%  
PC9  =  1.39%  
PC10 =  1.16%

ЁЯСЙ PC1 ржПржХрж╛ржЗ ржкрзНрж░рж╛рзЯ ржЕрж░рзНржзрзЗржХ information explain ржХрж░рзЗред

---

### тЦ╢ Cumulative Explained Variance
Cumulative variance after components:
- First 2 PCs  тЖТ ~63%
- First 5 PCs  тЖТ ~85%
- First 10 PCs тЖТ ~95%

ЁЯСЙ Only 10 components ржжрж┐рзЯрзЗржЗ dataset ржПрж░ 95% information retain ржХрж░рж╛ рж╕ржорзНржнржм рж╣рзЯрзЗржЫрзЗ,
ржпрж╛ dimensionality reduction ржПрж░ ржЬржирзНржп ржЦрзБржм effectiveред

---

## ЁЯзо PCA Transformed Data
After PCA:
- New Feature Shape: (569, 10)

Each Principal Component рж╣рж▓рзЛ original features ржПрж░ weighted combinationред

Example:
- PC1 heavily influenced by:
  mean radius, mean perimeter, mean area,
  mean concavity, mean concave points

- PC2 ржмрзЗрж╢рж┐ influenced by:
  mean texture, mean symmetry, mean fractal dimension

ЁЯСЙ This shows PCA successfully captured correlation among featuresред

---

## ЁЯдЦ Model Performance Comparison

### ЁЯФ╣ Without PCA
Accuracy: **98.60%**

### ЁЯФ╣ With PCA (10 Components)
Accuracy: **97.90%**

---

## ЁЯУМ Final Observation
- PCA ржХрж░рж╛рж░ ржкрж░ accuracy рж╕рж╛ржорж╛ржирзНржп ржХржорзЗржЫрзЗ
- ржХрж┐ржирзНрждрзБ feature рж╕ржВржЦрзНржпрж╛ 30 тЖТ 10 ржП ржирзЗржорзЗ ржПрж╕рзЗржЫрзЗ
- Model ржПржЦржи:
  тЬФ Faster  
  тЬФ Less complex  
  тЬФ Less prone to overfitting  

ЁЯСЙ Conclusion:
PCA is very effective when we want a balance between
**high performance** and **low dimensionality**.

---

## тЬЕ Conclusion (In Short)
- PCA successfully reduced dimensions
- Most variance captured by first few components
- Classification performance remains almost the same
- PCA is suitable for real-world ML pipelines

тЬи This analysis proves PCA is a powerful feature reduction technique.
